# E1：领域适应 (Domain Adaptation)——让模型成为领域专家

通用LLM虽然知识广博，但在面对特定专业领域（如法律、医学、金融）时，可能会出现对术语理解偏差、推理逻辑不符或生成风格不专业的问题。领域适应的目标，就是通过在大量领域内文本上进行训练，让LLM“浸泡”在领域语言中，使其获得该领域的“语感”。

这就像让一位**优秀的英语文学毕业生**去当**程序员**。他虽然语言基础很好，但需要先阅读大量的编程书籍、技术文档和开源代码（**持续预训练**），才能真正理解什么是“多态”、“闭包”，并学会用程序员的语言风格写注释和文档。

- **核心方法：** **持续预训练（Continued Pre-training）**。它使用与LLM初始预训练相同的无监督目标（如预测被遮盖的词），但只使用特定领域的数据集。
- **计算成本：** 这是微调方法中计算成本最高的，通常需要大量的GPU资源和时间，适用于对领域专业性要求极高的场景。

## **核心目标：让模型“懂行”**

通用LLM是在通用语料（如维基百科）上训练的，它可能不理解特定领域的术语、缩写和独特的语言风格。领域适应的目标，就是通过在该领域的文本上进行“补课”，让模型获得该领域的“语感”。

## **核心方法：持续预训练**

- **概念说明:**
    - 持续预训练（Continued Pre-training）使用与LLM初始预训练相同（或类似）的无监督目标（如预测被遮盖的词），但只使用特定领域的数据集。
    - **类比：** 这就像让一位**优秀的英语文学毕业生**去当**程序员**。他虽然语言基础很好，但需要先阅读大量的编程书籍、技术文档和开源代码（**持续预训练**），才能真正理解什么是“多态”、“闭包”，并学会用程序员的语言风格写注释和文档。
- **适用场景:**
    - 当RAG系统需要部署在高度专业的领域时，如法律、医疗、金融、学术研究等。
    - 当企业内部有大量的专有文档和“黑话”时。

## **实践考量**

- **数据集准备:** 需要准备大规模、高质量的领域纯文本数据。
- **计算成本:** 这是微调方法中计算成本最高的，通常需要大量的GPU资源和时间。
- **风险:** 存在“灾难性遗忘”的风险，即模型在学习领域知识后，可能会丧失部分通用知识。