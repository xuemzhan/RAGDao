# B1：高级嵌入技术——把握语义的核心

嵌入模型（Embedding Model）是语义检索的“引擎”，它负责将人类的语言（文本）转化为机器能够理解的数学语言（向量）。这个转化过程的质量，直接决定了语义空间的好坏。想象一个巨大的**宇宙星图**，每一颗星星都代表一段文本。一个优秀的嵌入模型，就像一位**智慧的天文学家**，他绘制的星图应该具备以下特点：

- **星系聚集：** 语义上相似的文本（例如，所有关于“苹果公司财务报告”的段落），在星图上会聚集在一起，形成一个紧密的“星系”。
- **星系分明：** 不同主题的文本（例如，“苹果公司”和“苹果派食谱”），在星图上会相距遥远，分属于不同的“星系”。
- **精细辨认：** 即便是同一个星系内部，它也能区分出细微的差别（例如，“2024年Q4财报”和“2025年Q1财报”的星星会很近，但不会完全重合）。

## **尝试不同的嵌入模型**

不存在一个“放之四海而皆准”的完美嵌入模型。不同的模型在不同的语言、领域和任务上表现各异。选择的起点应该是权威的排行榜和对自身任务的理解。

- **MTEB排行榜简介：**
    - MTEB（Massive Text Embedding Benchmark）是一个由社区驱动的、全面的文本嵌入模型评估基准，由Hugging Face等机构的研究人员于2022年提出。它已成为评估和比较嵌入模型的行业标准。您可以在Hugging Face上找到[MTEB排行榜](https://huggingface.co/spaces/mteb/leaderboard)。在排行榜上，重点关注Retrieval任务的平均分。同时，注意模型的维度（dim）、大小和支持的语言。
- **热门模型举例：**
    - **BGE (BAAI General Embedding):** 由中国智源人工智能研究院开发，长期霸榜，有多种尺寸和语言版本可选，是开源模型的绝佳选择。
    - **GTE (General Text Embeddings):** 另一个由一线研究机构推出的高性能开源模型。
    - **OpenAI text-embedding-3-small/large:** 闭源商用模型的标杆，性能强大，使用方便，但有API调用成本。

## **微调嵌入模型 (Fine-tuning)**

通用模型是在维基百科等通用语料上训练的，可能无法理解你公司内部的专有术语或“黑话”（例如，一个项目代号Project Phoenix在通用模型看来可能与神话有关，但在你公司内部明确指向某个软件）。微调（Fine-tuning）就是用你自己的数据，对预训练好的嵌入模型进行“再教育”，让它成为理解你特定领域语言的专家。

- **核心思想——对比学习：**
    - **类比：** 这就像是在训练一只**警犬**。你给它闻一下嫌疑人的**手套（anchor）**，然后告诉它，这个人穿过的鞋子（positive）是“好”的，应该去追；而另一个人用过的杯子（negative）是“坏”的，应该忽略。通过反复训练，警犬就学会了只追踪与嫌疑人相关的气味。
    - **训练数据：** 通常是三元组（Triplets）：(anchor, positive, negative)。anchor是查询或文本样本，positive是相关的文本，negative是不相关的文本。
- **实践中的数据集构建策略：**
    - **来自用户行为日志：** 这是最高质量的数据来源之一。例如，在电商搜索场景中，用户点击并购买的商品（positive）相比于那些曝光了但未被点击的商品（negative），构成了天然的训练样本。
    - **来自现有问答对 (FAQ):** 公司的FAQ页面是极佳的种子数据。问题可以作为anchor，对应的标准答案作为positive。negative可以从其他不相关的问答对中采样。
    - **LLM合成数据 (需要谨慎):** 如前所述，可以用LLM生成数据，但这需要高质量的Prompt和严格的质量控制，以防模型生成过于简单或模式化的数据，导致微调后的模型过拟合于这种“合成风格”。
    - **难负样本挖掘 (Hard Negative Mining):**
        - **概念说明：** 简单的negative样本（如“苹果公司财报” vs. “苹果派食谱”）很容易区分。但要让模型学会细微差别，需要“难负样本”，即那些与anchor主题相关但内容不符的样本（如“苹果Q1财报” vs. “苹果Q2财 ઉ报”）。
        - **实现方法：** 在训练过程中，可以先用当前模型进行一次检索，将那些被模型**错误地排在靠前位置**的不相关文档，作为下一轮训练的难负样本。这是一种迭代式的自适应训练。
- **可执行代码示例 (使用sentence-transformers进行微调的数据准备和训练):**

```python
# 准备环境:
# pip install sentence-transformers datasets

from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader
from datasets import Dataset

# 1. 准备微调数据集
# 在真实场景中，这些数据需要通过人工标注或业务日志挖掘得到。
# 这里我们创建一些简单的例子。
train_samples_data = {
    "query": [
        "What is the capital of France?", 
        "How does photosynthesis work?"
    ],
    "positive_doc": [
        "Paris is the most populous city and capital of France.",
        "Photosynthesis is a process used by plants to convert light energy into chemical energy."
    ],
    "negative_doc": [
        "The Eiffel Tower is a famous landmark in Paris.", # 与query相关，但不是直接答案，是一个"hard negative"
        "The mitochondria is the powerhouse of the cell." # 完全不相关
    ]
}
train_dataset = Dataset.from_dict(train_samples_data)

# 2. 将数据集转换为 sentence-transformers 需要的 InputExample 格式
train_examples = []
for i in range(train_dataset.num_rows):
    example = train_dataset[i]
    train_examples.append(InputExample(texts=[example['query'], example['positive_doc'], example['negative_doc']]))

# 3. 加载一个预训练模型作为微调的起点
model_name = 'all-MiniLM-L6-v2'
print(f"Loading pre-trained model: {model_name}")
model = SentenceTransformer(model_name)

# 4. 定义数据加载器和损失函数
# DataLoader负责将数据分批次提供给模型
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)
# TripletLoss 是对比学习中经典的三元组损失函数。
# 它的目标是让 (anchor, positive) 对的距离小于 (anchor, negative) 对的距离。
train_loss = losses.TripletLoss(model=model)

# 5. 执行微调
# 在真实项目中，num_epochs通常更大，并需要配置warmup_steps等参数。
print("Starting fine-tuning...")
model.fit(train_objectives=[(train_dataloader, train_loss)],
          epochs=1,
          warmup_steps=1,
          output_path='./finetuned_embedding_model', # 微调后的模型保存路径
          show_progress_bar=True)

print("\nFine-tuning complete. Model saved to './finetuned_embedding_model'")

# 6. (可选) 验证微调效果
finetuned_model = SentenceTransformer('./finetuned_embedding_model')

query = "What is the capital of France?"
docs_to_compare = [
    "Paris is the most populous city and capital of France.", # 正确答案
    "The Eiffel Tower is a famous landmark in Paris." # 干扰项
]

query_embedding = finetuned_model.encode(query)
doc_embeddings = finetuned_model.encode(docs_to_compare)

from sentence_transformers.util import cos_sim

scores = cos_sim(query_embedding, doc_embeddings)
print(f"\nScores after fine-tuning for query '{query}':")
print(f"'{docs_to_compare[0]}': {scores[0][0]:.4f}")
print(f"'{docs_to_compare[1]}': {scores[0][1]:.4f}")
# 期望看到正确答案的得分显著高于干扰项的得分。
```

## **多模态嵌入 (Multimodal Embeddings)**

知识不仅仅是文本。图表、图片、甚至音频都包含着丰富的信息。多模态嵌入模型（如OpenAI的CLIP）可以将不同模态的数据（如文本和图像）映射到同一个共享的向量空间中。这就像为全世界的不同语言（文本、图像、声音）发明了一种通用的“**世界语**”（共享向量空间）。一张猫的**图片**和“一只猫”这段**文字**，在这门世界语中会被翻译成几乎相同的“句子”（向量）。

- **应用场景:**
    - **图文互搜：** 用一句话描述来搜索知识库中的相关图片、图表。
    - **复杂文档理解：** 将文档中的图片和周围的文本一起嵌入，让系统能理解“如图1所示的系统架构...”这样的内容。
- **[图片建议]:** 一张图，左边是一张建筑物的图片，右边是一段文字描述“一栋有玻璃幕墙的现代摩天大楼”。从图片和文字分别引出箭头，指向同一个向量点[0.1, 0.8, ...]，图的标题是“多模态嵌入：图文同义”。