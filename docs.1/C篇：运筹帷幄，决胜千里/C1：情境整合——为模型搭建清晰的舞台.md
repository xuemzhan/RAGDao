# C1：情境整合——为模型搭建清晰的舞台

情境整合（Context Integration）研究的是如何将检索到的不同信息片段（上下文）、用户的原始查询以及对模型的指令，有效地组织和拼接成一个最终的提示。这就像是为一位演员（LLM）准备**剧本**。剧本的结构必须清晰，让演员一眼就能分清哪部分是**背景介绍（上下文）**，哪部分是**他的台词提示（问题）**，哪部分是**导演的特别指示（指令）**。如果剧本乱成一团，再好的演员也可能演砸。

## **建立清晰的信息层次结构**

一个结构化的Prompt能帮助LLM更好地理解不同信息模块的角色。关键在于建立清晰的信息层次：

- **系统指令 (System Instruction):** 位于最顶层，明确模型的角色、任务和核心行为准则。
- **检索上下文 (Retrieved Context):** 从外部知识库获取的相关信息，是模型回答问题的主要依据。
- **用户查询 (User Question):** 用户的原始问题，是模型需要解决的核心目标。
- **输出要求 (Output Requirements):** 对期望回答的格式、风格、长度等进行约束。

## **尝试不同的信息合并方式**

不同的LLM可能对提示中信息的排列顺序有不同的敏感度。没有绝对的最优解，但存在一些经过实践检验的有效模式。**常见模式举例：**

- **模式一：指令 -> 上下文 -> 问题 (最常用)**
    
    先告诉模型它的角色和规则，然后给它阅读材料，最后让它回答问题。符合人类的认知流程，逻辑清晰。
    
- **模式二：上下文 -> 问题 -> 指令**
    
    有时将指令放在最后，可以起到“强化提醒”的作用，尤其是在指令非常关键时（例如，“绝对禁止使用外部知识”）。
    

## **使用清晰的界限**

使用明确的分隔符，可以帮助模型在结构上区分不同的信息输入。这减少了模型将上下文内容误解为指令，或将问题误解为上下文的可能性。

- **巧妙设计——XML标签：**
    - **概念出处：** 使用XML标签来构建提示的实践，由Anthropic公司在其Claude模型的文档中大力推广，并被证明是一种非常有效和鲁棒的结构化提示方法。
    - **优点：** 结构化强，可嵌套，比简单的###或---更不容易产生歧义。
- **可执行代码示例 (使用XML标签构建Prompt):**

```python
def create_prompt_with_xml(instruction: str, context_list: list[str], question: str) -> str:
    """
    使用XML标签构建一个结构清晰的RAG Prompt。

    Args:
        instruction (str): 对LLM的核心指令。
        context_list (list[str]): 检索到的文档块列表。
        question (str): 用户的原始问题。

    Returns:
        str: 格式化后的完整Prompt。
    """
    # 将上下文文档列表格式化为带有索引的XML标签字符串
    # <document index="1">...</document>
    # <document index="2">...</document>
    context_str = "\n".join(
        f"<document index=\"{i+1}\">\n{doc}\n</document>" 
        for i, doc in enumerate(context_list)
    )
    
    # 将所有部分组合成最终的Prompt
    # 使用<instruction>, <context>, <question>, <answer>等标签清晰地划分区域
    prompt = f"""
    <instruction>
		{instruction}
		</instruction>
		<context>
		{context_str}
		</context>
		<question>
		{question}
		</question>
		<answer>
		"""
		return prompt
# --- 示例用法 ---
my_instruction = "Answer the user's question based strictly on the provided documents. Cite the document index for each piece of information using the format [index]."
my_docs = [
    "The first RAG paper was published by Lewis et al. in 2020.", 
    "RAG combines retrieval with generation to reduce hallucination."
]
my_question = "Who published the first RAG paper and what is its purpose?"

final_prompt = create_prompt_with_xml(my_instruction, my_docs, my_question)

print("--- Generated Prompt ---")
print(final_prompt)

# 模拟LLM可能的输出:
# The first RAG paper was published by Lewis et al. in 2020 [1]. 
# Its purpose is to combine retrieval with generation to reduce hallucination [2].
```

## **一个重要的陷阱——“迷失在中间 (Lost in the Middle)”：**

这个现象在2023年由多伦多大学、斯坦福大学和UC伯克利的研究人员在论文 "Lost in the Middle: How Language Models Use Long Contexts" 中被系统性地揭示。

- **现象：** 许多LLM在处理长上下文时，对开头和结尾部分的信息注意力最强，而对中间部分的信息容易“遗忘”。
- **应对策略：** 在将检索到的文档列表传入提示前，**将最相关的文档（例如，由重排器Reranker打分最高的文档）放在列表的开头或结尾**，而不是简单地按原始分数堆叠。**核心策略：优化文档排序 (Document Reordering)**
    - **方法：** 在将检索到的Top-K个文档送入Prompt之前，不要简单地按原始相关性分数（从高到低）排列。可以尝试以下策略：
        1. **“三明治”法：** 将最相关的1-2个文档放在上下文的**最开头**，将次相关的1-2个文档放在**最末尾**，其余的文档放在中间。
        2. **“反向”法：** 直接将文档按相关性**从低到高**排列。这强制模型在最后看到最关键的信息，可能会激发更好的表现。
    - **效果：** 这些看似简单的排序调整，在许多基准测试中已被证明能显著提升RAG在长上下文场景下的性能。

> 文档重排序对RAG性能的影响，在Neevon shoal等人2024年的论文 "Lost in the Middle no More: Improving Large Language Model Population Awareness" 等研究中有深入探讨。
>